{"cells":[{"cell_type":"markdown","metadata":{"id":"A3scn7NTHKfW"},"source":["# Weakly-supervised end-to-end PCa grading with Attention-guided Kernel Density Matrices (WiSDOM)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1690825377532,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"2gJ10tzOUybl","outputId":"4d5e0577-34c7-4135-9774-62cafbfd99e5"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"k97E2G2wHQuC"},"source":["## Imports, libs, storage, wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4826,"status":"ok","timestamp":1690825472438,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"o0XZwbTl7IQy","outputId":"bc16dd42-39a2-4270-8f63-91d38cf41092"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import wandb\n","from keras import optimizers\n","from keras.layers import Input, Dense\n","import keras\n","import os\n","import pandas as pd\n","from collections import OrderedDict\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import classification_report, ConfusionMatrixDisplay, mean_absolute_error, cohen_kappa_score, pairwise_distances\n","from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{"id":"Q1kX_0gPQdng"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"9tqHmJGVGlUw"},"source":["#### Load Dataframes\n","\n","Do some cleaning as well"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cr8UrLcy7Eyn"},"outputs":[],"source":["df_train = pd.read_csv(\"/root/data/KDM/data/wsi_train.csv\") \n","df_val = pd.read_csv(\"/root/data/KDM/data/wsi_val.csv\")\n","df_test = pd.read_csv(\"/root/data/KDM/data/wsi_test.csv\")\n","train_dict = df_train.set_index('image_id')['isup_grade'].to_dict(into=OrderedDict)\n","val_dict = df_val.set_index('image_id')['isup_grade'].to_dict(into=OrderedDict)\n","test_dict = df_test.set_index('image_id')['isup_grade'].to_dict(into=OrderedDict)\n","train_dict = {k: v for k, v in train_dict.items() if os.path.isfile(os.path.join('/root/data/KDM/data/tile_mosaics',k+'.jpeg'))}\n","val_dict = {k: v for k, v in val_dict.items() if os.path.isfile(os.path.join('/root/data/KDM/data/tile_mosaics',k+'.jpeg'))}\n","test_dict = {k: v for k, v in test_dict.items() if os.path.isfile(os.path.join('/root/data/KDM/data/tile_mosaics',k+'.jpeg'))}\n","del train_dict['1c36b3db47d83f1436bd260288c5723f']\n","del train_dict['50203fbd5de280144cbb16749814a3fe']\n","del test_dict['ecae863e7c478594aa4c84ce132b3825']\n","\n","train_features = list(train_dict.keys())\n","train_labels = np.array(list(train_dict.values()))\n","val_features = list(val_dict.keys())\n","val_labels = np.array(list(val_dict.values()))\n","test_features = list(test_dict.keys())\n","test_labels = np.array(list(test_dict.values()))\n","train_paths = [os.path.join('/root/data/KDM/data/tile_mosaics',train_path+'.jpeg') for train_path in train_features]\n","val_paths = [os.path.join('/root/data/KDM/data/tile_mosaics',val_path+'.jpeg') for val_path in val_features]\n","test_paths = [os.path.join('/root/data/KDM/data/tile_mosaics',test_path+'.jpeg') for test_path in test_features]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nLRfZMUPTrc"},"outputs":[],"source":["for k, v, i in zip(train_features, train_labels, train_dict.items()):\n","  assert k == i[0] and v == i[1]\n"]},{"cell_type":"markdown","metadata":{"id":"AeL_MV-oPQaG"},"source":["### Preprocessing\n","\n","Helper functions to load a sample from storage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gR6t2ZziPRpt"},"outputs":[],"source":["def decode_img(img):\n","  # Convert the compressed string to a 3D uint8 tensor\n","  img = tf.io.decode_jpeg(img, channels=3)\n","  # Resize the image to the desired size\n","  return img\n","\n","def process_path(file_path, label):\n","  # Load the raw data from the file as a string\n","  img = tf.io.read_file(file_path)\n","  img = decode_img(img)\n","  #img = tf.cast(img, tf.float32) / 255.0\n","  return img, label\n","\n","def process_sample(file_path):\n","  # Load the raw data from the file as a string\n","  img = tf.io.read_file(file_path)\n","  img = decode_img(img)\n","  img = tf.cast(img, tf.float32) / 255.0\n","  return img\n"]},{"cell_type":"markdown","metadata":{"id":"wCsMM66eGwRg"},"source":["#### One hot encoding of the labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffxLI5GXtRyf"},"outputs":[],"source":["encoder = OneHotEncoder()\n","y_train_onehot = encoder.fit_transform(train_labels.reshape(-1,1))\n","y_train_one_hot = y_train_onehot.toarray()\n","y_val_onehot = encoder.fit_transform(val_labels.reshape(-1,1))\n","y_val_one_hot = y_val_onehot.toarray()\n","y_test_onehot = encoder.fit_transform(test_labels.reshape(-1,1))\n","y_test_one_hot = y_test_onehot.toarray()"]},{"cell_type":"markdown","metadata":{"id":"SZHcaV6UxXtv"},"source":["#### Regression Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0ROTTM9xXZL"},"outputs":[],"source":["train_reg_labels = train_labels / 5\n","val_reg_labels = val_labels / 5\n","test_reg_labels = test_labels / 5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1690825485607,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"wYhpymVixm4-","outputId":"52ab2c00-d7c6-47fd-ef2b-8f827dfd1df7"},"outputs":[],"source":["np.unique(train_reg_labels, return_counts=True)"]},{"cell_type":"markdown","metadata":{"id":"v5gCvF8mwRHm"},"source":["## Datasets"]},{"cell_type":"markdown","metadata":{"id":"WDlpe7ryGc-6"},"source":["#### Batch size\n","\n","For A100 largest batch size that fits is 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjlOYtyfu7L5"},"outputs":[],"source":["batch_size = 8"]},{"cell_type":"markdown","metadata":{"id":"8Tnwlxs2GQQK"},"source":["#### Dataset class that returns a WSI mosaic\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyLKIoRGfdxT"},"outputs":[],"source":["def create_dataset(paths,labels,batch_size,shuffle=False):\n","  num_samples = len(labels)\n","  paths = tf.data.Dataset.from_tensor_slices(paths)\n","  labels = tf.data.Dataset.from_tensor_slices(labels)\n","  ds = tf.data.Dataset.zip((paths,labels))\n","  if shuffle:\n","    ds = ds.shuffle(buffer_size=num_samples)\n","  ds = ds.map(process_path)\n","  ds = ds.batch(batch_size)\n","  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n","  return ds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-83yNJ9whwpl"},"outputs":[],"source":["train_dataset_one_hot = create_dataset(train_paths, y_train_one_hot, batch_size=4, shuffle=True)\n","train_dataset = create_dataset(train_paths, train_reg_labels, batch_size=4, shuffle=True)\n","val_dataset = create_dataset(val_paths, val_reg_labels, shuffle=False, batch_size=4)\n","test_dataset = create_dataset(test_paths, test_reg_labels, shuffle=False, batch_size=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zFJ5snkje_xm"},"outputs":[],"source":["def get_samples_from_each_class(dataset, n_samples):\n","    samples_per_class = {class_idx: [] for class_idx in range(6)}\n","    samples_found_per_class = {class_idx: 0 for class_idx in range(6)}\n","    samples_collected = 0\n","\n","    for batch_samples, batch_labels in dataset:\n","        for sample, label in zip(batch_samples, batch_labels):\n","            class_idx = np.argmax(label)\n","            if samples_found_per_class[class_idx] < n_samples:\n","                samples_per_class[class_idx].append(sample)\n","                samples_found_per_class[class_idx] += 1\n","                samples_collected += 1\n","\n","            if samples_collected == n_samples * 6:\n","                break\n","\n","        if samples_collected == n_samples * 6:\n","            break\n","\n","    stacked_samples = tf.stack([sample for samples_list in samples_per_class.values() for sample in samples_list])\n","    stacked_labels = tf.stack([tf.one_hot(class_idx, depth=6) for class_idx, samples_list in samples_per_class.items() for _ in range(n_samples)])\n","\n","    return stacked_samples, stacked_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6r3EgWwcfBha"},"outputs":[],"source":["prototypes, prototype_labels = get_samples_from_each_class(train_dataset_one_hot, 36)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1690825491738,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"EsL-PfQsTA9H","outputId":"ed10b577-3993-433c-8a91-938357573256"},"outputs":[],"source":["prototypes.shape"]},{"cell_type":"markdown","metadata":{"id":"UEWYd_fbQWMv"},"source":["## KDM"]},{"cell_type":"markdown","metadata":{"id":"_DyOstFfOP20"},"source":["### Patches"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uoUmeF0cb_q"},"outputs":[],"source":["class Patches(tf.keras.layers.Layer):\n","    def __init__(self, patch_size, image_size, strides):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","        self.strides = strides\n","        self.num_patches = (image_size - patch_size) // strides + 1\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.strides, self.strides, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, self.num_patches ** 2, patch_dims])\n","        return patches"]},{"cell_type":"markdown","metadata":{"id":"x7TRjcR4OR1p"},"source":["### KDM Functions and Kernels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpSAlJJn7euC"},"outputs":[],"source":["from keras.backend import dtype\n","def dm2comp(dm):\n","    '''\n","    Extract vectors and weights from a factorized density matrix representation\n","    Arguments:\n","     dm: tensor of shape (bs, n, d + 1)\n","    Returns:\n","     w: tensor of shape (bs, n)\n","     v: tensor of shape (bs, n, d)\n","    '''\n","    return dm[:, :, 0], dm[:, :, 1:]\n","\n","\n","def comp2dm(w, v):\n","    '''\n","    Construct a factorized density matrix from vectors and weights\n","    Arguments:\n","     w: tensor of shape (bs, n)\n","     v: tensor of shape (bs, n, d)\n","    Returns:\n","     dm: tensor of shape (bs, n, d + 1)\n","    '''\n","    return tf.concat((w[:, :, tf.newaxis], v), axis=2)\n","\n","def samples2dm(samples):\n","    '''\n","    Construct a factorized density matrix from a batch of samples\n","    each sample will have the same weight. Samples that are all\n","    zero will be ignored.\n","    Arguments:\n","        samples: tensor of shape (bs, n, d)\n","    Returns:\n","        dm: tensor of shape (bs, n, d + 1)\n","    '''\n","    w = tf.reduce_any(samples, axis=-1)\n","    w = w / tf.reduce_sum(w, axis=-1, keepdims=True)\n","    return comp2dm(w, samples)\n","\n","def pure2dm(psi):\n","    '''\n","    Construct a factorized density matrix to represent a pure state\n","    Arguments:\n","     psi: tensor of shape (bs, d)\n","    Returns:\n","     dm: tensor of shape (bs, 1, d + 1)\n","    '''\n","    ones = tf.ones_like(psi[:, 0:1])\n","    dm = tf.concat((ones[:,tf.newaxis, :],\n","                    psi[:,tf.newaxis, :]),\n","                   axis=2)\n","    return dm\n","\n","\n","def dm2discrete(dm):\n","    '''\n","    Creates a discrete distribution from the components of a density matrix\n","    Arguments:\n","     dm: tensor of shape (bs, n, d + 1)\n","    Returns:\n","     prob: vector of probabilities (bs, d)\n","    '''\n","    w, v = dm2comp(dm)\n","    w = w / tf.reduce_sum(w, axis=-1, keepdims=True)\n","    norms_v = tf.expand_dims(tf.linalg.norm(v, axis=-1), axis=-1)\n","    v = v / norms_v\n","    probs = tf.einsum('...j,...ji->...i', w, v ** 2, optimize=\"optimal\")\n","    return probs\n","\n","\n","def dm2distrib(dm, sigma):\n","    '''\n","    Creates a Gaussian mixture distribution from the components of a density\n","    matrix with an RBF kernel\n","    Arguments:\n","     dm: tensor of shape (bs, n, d + 1)\n","     sigma: sigma parameter of the RBF kernel\n","    Returns:\n","     gm: mixture of Gaussian distribution with shape (bs, )\n","    '''\n","    w, v = dm2comp(dm)\n","    v = tf.cast(v, tf.float32)\n","    sigma = tf.cast(sigma, tf.float32)\n","    gm = tfd.MixtureSameFamily(reparameterize=True,\n","            mixture_distribution=tfd.Categorical(\n","                                    probs=w),\n","            components_distribution=tfd.Independent( tfd.Normal(\n","                    loc=v,  # component 2\n","                    scale=sigma / np.sqrt(2.)),\n","                    reinterpreted_batch_ndims=1))\n","    return gm\n","\n","\n","def pure_dm_overlap(x, dm, kernel):\n","    '''\n","    Calculates the overlap of a state  \\phi(x) with a density\n","    matrix in a RKHS defined by a kernel\n","    Arguments:\n","      x: tensor of shape (bs, d)\n","     dm: tensor of shape (bs, n, d + 1)\n","     kernel: kernel function\n","              k: (bs, d) x (bs, n, d) -> (bs, n)\n","    Returns:\n","     overlap: tensor with shape (bs, )\n","    '''\n","    w, v = dm2comp(dm)\n","    overlap = tf.einsum('...i,...i->...', w, kernel(x, v) ** 2)\n","    return overlap\n","\n","## Kernels\n","\n","class CompTransKernelLayer(tf.keras.layers.Layer):\n","    def __init__(self, transform, kernel):\n","        '''\n","        Composes a transformation and a kernel to create a new\n","        kernel.\n","        Arguments:\n","            transform: a function f that transform the input before feeding it to the\n","                    kernel\n","                    f:(bs, d) -> (bs, D)\n","            kernel: a kernel function\n","                    k:(bs, n, D)x(m, D) -> (bs, n, m)\n","        '''\n","        super(CompTransKernelLayer, self).__init__()\n","        self.transform = transform\n","        self.kernel = kernel\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        shape = tf.shape(A) # (bs, n, d)\n","        A = tf.reshape(A, [shape[0] * shape[1], shape[2]])\n","        A = self.transform(A)\n","        dim_out = tf.shape(A)[1]\n","        A = tf.reshape(A, [shape[0], shape[1], dim_out])\n","        B = self.transform(B)\n","        return self.kernel(A, B)\n","\n","    def log_weight(self):\n","        return self.kernel.log_weight()\n","\n","class RBFKernelLayer(tf.keras.layers.Layer):\n","    def __init__(self, sigma, dim, trainable=True, min_sigma=1e-3):\n","        '''\n","        Builds a layer that calculates the rbf kernel between two set of vectors\n","        Arguments:\n","            sigma: RBF scale parameter. If it is a tf.Variable it will be used as is.\n","                     Otherwise it will create a trainable variable with the given value.\n","        '''\n","        super(RBFKernelLayer, self).__init__()\n","        if type(sigma) is tf.Variable:\n","            self.sigma = sigma\n","        else:\n","            self.sigma = tf.Variable(sigma, dtype=tf.float32, trainable=trainable)\n","        self.dim = dim\n","        self.min_sigma = min_sigma\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        shape_A = tf.shape(A)\n","        shape_B = tf.shape(B)\n","        A_norm = tf.norm(A, axis=-1)[..., tf.newaxis] ** 2\n","        B_norm = tf.norm(B, axis=-1)[tf.newaxis, tf.newaxis, :] ** 2\n","        A_reshaped = tf.reshape(A, [-1, shape_A[2]])\n","        AB = tf.matmul(A_reshaped, B, transpose_b=True)\n","        AB = tf.reshape(AB, [shape_A[0], shape_A[1], shape_B[0]])\n","        dist2 = A_norm + B_norm - 2. * AB\n","        dist2 = tf.clip_by_value(dist2, 0., np.inf)\n","        sigma = tf.clip_by_value(self.sigma, self.min_sigma, np.inf)\n","        K = tf.exp(-dist2 / (2. * sigma ** 2.))\n","        return K\n","\n","    def log_weight(self):\n","        sigma = tf.clip_by_value(self.sigma, self.min_sigma, np.inf)\n","        return - self.dim * tf.math.log(sigma + 1e-12) - self.dim * np.log(4 * np.pi)\n","\n","\n","\n","'''\n","Keras layer version of CosineKernel\n","'''\n","class CosineKernelLayer(tf.keras.layers.Layer):\n","    def __init__(self):\n","        '''\n","        Builds a layer that calculates the cosine kernel between two set of vectors\n","        '''\n","        super(CosineKernelLayer, self).__init__()\n","        self.eps = 1e-6\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        A = tf.math.divide_no_nan(A,\n","                                  tf.expand_dims(tf.norm(A, axis=-1), axis=-1))\n","        B = tf.math.divide_no_nan(B,\n","                                  tf.expand_dims(tf.norm(B, axis=-1), axis=-1))\n","        K = tf.einsum(\"...nd,md->...nm\", A, B)\n","        return K\n","\n","    def log_weight(self):\n","        return 0\n","\n","\n","class CrossProductKernelLayer(tf.keras.layers.Layer):\n","\n","    def __init__(self, dim1, kernel1, kernel2):\n","        '''\n","        Create a layer that calculates the cross product kernel of two input\n","        kernels. The input vector are divided into two parts, the first of dimension\n","        dim1 and the second of dimension d - dim1. Each input kernel is applied to\n","        one of the parts of the input.\n","        Arguments:\n","            dim1: the dimension of the first part of the input vector\n","            kernel1: a kernel function\n","                    k1:(bs, n, dim1)x(m, dim1) -> (bs, n, m)\n","            kernel2: a kernel function\n","                    k2:(bs, n, d - dim1)x(m, d - dim1) -> (bs, n, m)\n","        '''\n","\n","        super(CrossProductKernelLayer, self).__init__()\n","        self.dim1 = dim1\n","        self.kernel1 = kernel1\n","        self.kernel2 = kernel2\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        A1 = A[:, :, :self.dim1]\n","        A2 = A[:, :, self.dim1:]\n","        B1 = B[:, :self.dim1]\n","        B2 = B[:, self.dim1:]\n","        return self.kernel1(A1, B1) * self.kernel2(A2, B2)\n","\n","    def log_weight(self):\n","        return self.kernel1.log_weight() + self.kernel2.log_weight()\n","\n","## Layers and models\n","\n","def l1_loss(vals):\n","    '''\n","    Calculate the l1 loss for a batch of vectors\n","    Arguments:\n","        vals: tensor with shape (b_size, n)\n","    '''\n","    b_size = tf.cast(tf.shape(vals)[0], dtype=tf.float32)\n","    vals = vals / tf.norm(vals, axis=1)[:, tf.newaxis]\n","    loss = tf.reduce_sum(tf.abs(vals)) / b_size\n","    return loss\n","\n","class KDMUnit(tf.keras.layers.Layer):\n","    \"\"\"Kernel Density Matrix Unit\n","    Receives as input a factored density matrix represented by a set of vectors\n","    and weight values.\n","    Returns a resulting factored density matrix.\n","    Input shape:\n","        (batch_size, n_comp_in, dim_x + 1)\n","        where dim_x is the dimension of the input state\n","        and n_comp_in is the number of components of the input factorization.\n","        The weights of the input factorization of sample i are [i, :, 0],\n","        and the vectors are [i, :, 1:dim_x + 1].\n","    Output shape:\n","        (batch_size, n_comp, dim_y)\n","        where dim_y is the dimension of the output state\n","        and n_comp is the number of components used to represent the train\n","        density matrix. The weights of the\n","        output factorization for sample i are [i, :, 0], and the vectors\n","        are [i, :, 1:dim_y + 1].\n","    Arguments:\n","        dim_x: int. the dimension of the input state\n","        dim_y: int. the dimension of the output state\n","        x_train: bool. Whether to train or not the x compoments of the train\n","                       density matrix.\n","        x_train: bool. Whether to train or not the y compoments of the train\n","                       density matrix.\n","        w_train: bool. Whether to train or not the weights of the compoments\n","                       of the train density matrix.\n","        n_comp: int. Number of components used to represent\n","                 the train density matrix\n","        l1_act: float. Coefficient of the regularization term penalizing the l1\n","                       norm of the activations.\n","        l1_x: float. Coefficient of the regularization term penalizing the l1\n","                       norm of the x components.\n","        l1_y: float. Coefficient of the regularization term penalizing the l1\n","                       norm of the y components.\n","    \"\"\"\n","    def __init__(\n","            self,\n","            kernel,\n","            dim_x: int,\n","            dim_y: int,\n","            x_train: bool = True,\n","            y_train: bool = True,\n","            w_train: bool = True,\n","            n_comp: int = 0,\n","            l1_x: float = 0.,\n","            l1_y: float = 0.,\n","            l1_act: float = 0.,\n","            **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","        self.kernel = kernel\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.x_train = x_train\n","        self.y_train = y_train\n","        self.w_train = w_train\n","        self.n_comp = n_comp\n","        self.l1_x = l1_x\n","        self.l1_y = l1_y\n","        self.l1_act = l1_act\n","        self.c_x = self.add_weight(\n","            \"c_x\",\n","            shape=(self.n_comp, self.dim_x),\n","            #initializer=tf.keras.initializers.orthogonal(),\n","            initializer=tf.keras.initializers.random_normal(),\n","            trainable=self.x_train)\n","        self.c_y = self.add_weight(\n","            \"c_y\",\n","            shape=(self.n_comp, self.dim_y),\n","            initializer=tf.keras.initializers.Constant(np.sqrt(1./self.dim_y)),\n","            #initializer=tf.keras.initializers.random_normal(),\n","            trainable=self.y_train)\n","        self.comp_w = self.add_weight(\n","            \"comp_w\",\n","            shape=(self.n_comp,),\n","            initializer=tf.keras.initializers.constant(1./self.n_comp),\n","            trainable=self.w_train)\n","        self.eps = 1e-10\n","\n","    def call(self, inputs):\n","        # Weight regularizers\n","        if self.l1_x != 0:\n","            self.add_loss(self.l1_x * l1_loss(self.c_x))\n","        if self.l1_y != 0:\n","            self.add_loss(self.l1_y * l1_loss(self.c_y))\n","        #comp_w = tf.clip_by_value(self.comp_w, 1e-10, 1)\n","        comp_w = tf.abs(self.comp_w) + 1e-6\n","        # normalize comp_w to sum to 1\n","        comp_w = comp_w / tf.reduce_sum(comp_w)\n","        in_w = inputs[:, :, 0]  # shape (b, n_comp_in)\n","        in_v = inputs[:, :, 1:] # shape (b, n_comp_in, dim_x)\n","        out_vw = self.kernel(in_v, self.c_x)  # shape (b, n_comp_in, n_comp)\n","        out_w = (tf.expand_dims(tf.expand_dims(comp_w, axis=0), axis=0) *\n","                 tf.square(out_vw)) # shape (b, n_comp_in, n_comp)\n","        out_w = tf.maximum(out_w, self.eps) #########\n","        # out_w_sum = tf.maximum(tf.reduce_sum(out_w, axis=2), self.eps)  # shape (b, n_comp_in)\n","        out_w_sum = tf.reduce_sum(out_w, axis=2) # shape (b, n_comp_in)\n","        out_w = out_w / tf.expand_dims(out_w_sum, axis=2)\n","        out_w = tf.einsum('...i,...ij->...j', in_w, out_w, optimize=\"optimal\")\n","                # shape (b, n_comp)\n","        if self.l1_act != 0:\n","            self.add_loss(self.l1_act * l1_loss(out_w))\n","        out_w = tf.expand_dims(out_w, axis=-1) # shape (b, n_comp, 1)\n","        out_y_shape = tf.shape(out_w) + tf.constant([0, 0, self.dim_y - 1])\n","        out_y = tf.broadcast_to(tf.expand_dims(self.c_y, axis=0), out_y_shape)\n","        out = tf.concat((out_w, out_y), 2)\n","        return out\n","\n","    def get_config(self):\n","        config = {\n","            \"dim_x\": self.dim_x,\n","            \"dim_y\": self.dim_y,\n","            \"n_comp\": self.n_comp,\n","            \"x_train\": self.x_train,\n","            \"y_train\": self.y_train,\n","            \"w_train\": self.w_train,\n","            \"l1_x\": self.l1_x,\n","            \"l1_y\": self.l1_y,\n","            \"l1_act\": self.l1_act,\n","        }\n","        base_config = super().get_config()\n","        return {**base_config, **config}\n","\n","    def compute_output_shape(self, input_shape):\n","        return (self.dim_y + 1, self.n_comp)\n","\n","class KDMOverlap(tf.keras.layers.Layer):\n","    \"\"\"Kernel Density Matrix Overlap Unit\n","    Receives as input a vector and calculates its overlap with the unit density\n","    matrix.\n","    Input shape:\n","        (batch_size, dim_x)\n","        where dim_x is the dimension of the input state\n","    Output shape:\n","        (batch_size, )\n","    Arguments:\n","        kernel: a kernel function\n","        dim_x: int. the dimension of the input state\n","        x_train: bool. Whether to train the or not the compoments of the train\n","                       density matrix.\n","        w_train: bool. Whether to train the or not the weights of the compoments\n","                       of the train density matrix.\n","        n_comp: int. Number of components used to represent\n","                 the train density matrix\n","    \"\"\"\n","\n","    def __init__(\n","            self,\n","            kernel,\n","            dim_x: int,\n","            x_train: bool = True,\n","            w_train: bool = True,\n","            n_comp: int = 0,\n","            **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","        self.kernel = kernel\n","        self.dim_x = dim_x\n","        self.x_train = x_train\n","        self.w_train = w_train\n","        self.n_comp = n_comp\n","        self.c_x = self.add_weight(\n","            \"c_x\",\n","            shape=(self.n_comp, self.dim_x),\n","            #initializer=tf.keras.initializers.orthogonal(),\n","            initializer=tf.keras.initializers.random_normal(),\n","            trainable=self.x_train)\n","        self.comp_w = self.add_weight(\n","            \"comp_w\",\n","            shape=(self.n_comp,),\n","            initializer=tf.keras.initializers.constant(1./self.n_comp),\n","            trainable=self.w_train)\n","\n","    def call(self, inputs):\n","        #comp_w = tf.clip_by_value(self.comp_w, 1e-10, 1)\n","        comp_w = tf.abs(self.comp_w)\n","        # normalize comp_w to sum to 1\n","        comp_w = comp_w / tf.reduce_sum(comp_w)\n","        in_v = inputs[:, tf.newaxis, :]\n","        out_vw = self.kernel(in_v, self.c_x) ** 2 # shape (b, 1, n_comp)\n","        out_w = tf.einsum('...j,...ij->...', comp_w, out_vw, optimize=\"optimal\")\n","        return out_w\n","\n","    def get_config(self):\n","        config = {\n","            \"dim_x\": self.dim_x,\n","            \"n_comp\": self.n_comp,\n","            \"x_train\": self.x_train,\n","            \"w_train\": self.w_train,\n","        }\n","        base_config = super().get_config()\n","        return {**base_config, **config}\n","\n","    def compute_output_shape(self, input_shape):\n","        return (1,)\n","\n","class KDMClassModel(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 dim_y,\n","                 sigma,\n","                 n_comp,\n","                 x_train=True):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.n_comp = n_comp\n","        self.kernel_x = RBFKernelLayer(sigma, dim=dim_x)\n","        self.kdmu = KDMUnit(self.kernel_x,\n","                            dim_x=dim_x,\n","                            dim_y=dim_y,\n","                            n_comp=n_comp,\n","                            x_train=x_train)\n","\n","    def call(self, inputs):\n","        rho_x = pure2dm(inputs)\n","        rho_y = self.kdmu(rho_x)\n","        probs = dm2discrete(rho_y)\n","        return probs\n","\n","class BagKDMClassModel(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 dim_y,\n","                 sigma,\n","                 n_comp,\n","                 x_train=True,\n","                 l1_y=0.):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.n_comp = n_comp\n","        kernel_x = RBFKernelLayer(sigma)\n","        self.kdmu = KDMUnit(kernel_x,\n","                            dim_x=dim_x,\n","                            dim_y=dim_y,\n","                            n_comp=n_comp,\n","                            x_train=x_train,\n","                            l1_y=l1_y)\n","\n","    def call(self, inputs):\n","        in_shape = tf.shape(inputs)\n","        w = tf.ones_like(inputs[:, :, 0]) / in_shape[1]\n","        rho_x = comp2dm(w, inputs)\n","        rho_y = self.kdmu(rho_x)\n","        probs = dm2discrete(rho_y)\n","        return rho_y\n","\n","class KDMDenEstModel(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 sigma,\n","                 n_comp):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.n_comp = n_comp\n","        self.kernel = RBFKernelLayer(sigma, dim=dim_x)\n","        self.kdmover = KDMOverlap(self.kernel,\n","                                dim_x=dim_x,\n","                                n_comp=n_comp)\n","\n","    def call(self, inputs):\n","        log_probs = (tf.math.log(self.kdmover(inputs) + 1e-12)\n","                     + self.kernel.log_weight())\n","        self.add_loss(-tf.reduce_mean(log_probs))\n","        return log_probs\n","\n","\n","class KDMDenEstModel2(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 dim_y,\n","                 sigma,\n","                 n_comp,\n","                 trainable_sigma=True,\n","                 min_sigma=1e-3):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.n_comp = n_comp\n","        self.kernel_x = RBFKernelLayer(sigma, dim=dim_x,\n","                                       trainable=trainable_sigma,\n","                                       min_sigma=min_sigma)\n","        self.kernel_y = CosineKernelLayer()\n","        self.kernel = CrossProductKernelLayer(dim1=dim_x, kernel1=self.kernel_x, kernel2=self.kernel_y)\n","        self.kdmover = KDMOverlap(self.kernel,\n","                                dim_x=dim_x + dim_y,\n","                                n_comp=n_comp)\n","\n","    def call(self, inputs):\n","        log_probs = (tf.math.log(self.kdmover(inputs) + 1e-12)\n","                     + self.kernel.log_weight())\n","        self.add_loss(-tf.reduce_mean(log_probs))\n","        return log_probs"]},{"cell_type":"markdown","metadata":{"id":"EFderLJ5SuRM"},"source":["### KDM Attn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MUcz2OIbi7Q"},"outputs":[],"source":["class ProbRegression(tf.keras.layers.Layer):\n","    \"\"\"\n","    Calculates the expected value and variance of a measure on a\n","    density matrix. The measure associates evenly distributed values\n","    between 0 and 1 to the different n basis states.\n","    Input shape:\n","        A tensor with shape (batch_size, n)\n","    Output shape:\n","        (batch_size, n, 2)\n","    Arguments:\n","    \"\"\"\n","\n","    def __init__(\n","            self,\n","            **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","\n","\n","    def build(self, input_shape):\n","        if len(input_shape) != 2 :\n","            raise ValueError('A `DensityMatrix2Dist` layer should be '\n","                             'called with a tensor of shape '\n","                             '(batch_size, n)')\n","        self.vals = tf.constant(tf.linspace(0.0, 1.0, input_shape[1]), dtype=tf.float32)\n","        self.vals2 = self.vals ** 2\n","        self.built = True\n","\n","    def call(self, inputs):\n","        if len(inputs.shape) != 2:\n","            raise ValueError('A `DensityMatrix2Dist` layer should be '\n","                             'called with a tensor of shape '\n","                             '(batch_size, n, )')\n","        mean = tf.einsum('...i,i->...', inputs, self.vals, optimize='optimal')\n","        mean2 = tf.einsum('...i,i->...', inputs, self.vals2, optimize='optimal')\n","        var = mean2 - mean ** 2\n","        return tf.stack([mean, var], axis = -1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[1], 2)\n","\n","\n","class KDMAttentionLayer(tf.keras.layers.Layer):\n","    def __init__(self,\n","                 dim_h,\n","                 dense_units_1,\n","                 dense_units_2):\n","        super().__init__()\n","        self.dim_h = dim_h\n","        self.dense_units_1 = dense_units_1\n","        self.dense_units_2 = dense_units_2\n","        self.mlp_1 = tf.keras.Sequential([\n","                Dense(dense_units_1, activation='relu'),\n","                Dense(dim_h, activation='linear')])\n","        self.mlp_2 = tf.keras.Sequential([\n","                Dense(dense_units_2, activation='relu'),\n","                Dense(1, activation='linear')])\n","    def call(self, input):\n","        z_local = self.mlp_1(input)\n","        z_global = tf.reduce_mean(z_local, axis=1)\n","        z_global = tf.expand_dims(z_global, axis=1)\n","\n","        z_global = tf.broadcast_to(z_global, tf.shape(z_local))\n","        z = tf.concat([z_local, z_global], axis=-1)\n","        z = self.mlp_2(z)\n","        z = tf.squeeze(z, axis=-1) # eliminate the last dimension which should be 1\n","        w = tf.nn.softmax(z)\n","        return w"]},{"cell_type":"markdown","metadata":{"id":"7uchRekNuHKk"},"source":["## Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"McgaOu4NuImK"},"outputs":[],"source":["class KDMPatchRegressionModel(tf.keras.Model):\n","    def __init__(self,\n","                 patch_size,\n","                 image_size,\n","                 strides,\n","                 encoder,\n","                 encoded_size,\n","                 dim_y,\n","                 n_comp,\n","                 sigma=0.1,\n","                 attention=False,\n","                 attention_dim_h=64,\n","                 attention_dense_units_1=64,\n","                 attention_dense_units_2=64):\n","        super().__init__()\n","        self.patch_size = patch_size\n","        self.image_size = image_size\n","        self.strides = strides\n","        self.patch_layer = Patches(patch_size, image_size, strides)\n","        self.dim_y = dim_y\n","        self.encoded_size = encoded_size\n","        self.encoder = encoder\n","        self.n_comp = n_comp\n","        self.attention = attention\n","        self.sigma = sigma\n","        self.kernel = RBFKernelLayer(sigma=sigma,\n","                                         dim=encoded_size,\n","                                         trainable=True)\n","        self.kdm_unit = KDMUnit(kernel=self.kernel,\n","                                       dim_x=encoded_size,\n","                                       dim_y=dim_y,\n","                                       n_comp=n_comp)\n","        if attention:\n","            self.attention_layer = KDMAttentionLayer(dim_h=attention_dim_h,\n","                                              dense_units_1=attention_dense_units_1,\n","                                              dense_units_2=attention_dense_units_2)\n","        self.regression_layer = ProbRegression()\n","\n","\n","    def call(self, input): # (bs, 1152,1152,3)\n","        patches = self.patch_layer(input) #(bs, n_patches, w*h*c)\n","        encoded = self.encoder(patches) #()\n","        bs = tf.shape(encoded)[0]\n","        if self.attention:\n","            w = self.attention_layer(encoded)\n","        else:\n","            w = tf.ones((bs, self.patch_layer.num_patches ** 2,)) / (self.patch_layer.num_patches ** 2)\n","        rho_x = comp2dm(w, encoded)\n","        rho_y = self.kdm_unit(rho_x)\n","        # distrib = dm2distrib(rho_y,self.sigma)\n","        # mean = distrib.mean()\n","        # variance = distrib.variance()\n","        probs = dm2discrete(rho_y)\n","        mean_var = self.regression_layer(probs)\n","\n","        return mean_var\n","\n","    def init_components(self, samples_x, samples_y, init_sigma=False, sigma_mult=1):\n","        patches = self.patch_layer(samples_x)\n","        idx = tf.random.uniform(shape=(patches.shape[0],), maxval=patches.shape[1], dtype=tf.int32) #select 1 random patch from each mosaic\n","        # Select the desired patches using tf.gather\n","        selected_patches = tf.gather(patches, idx, axis=1, batch_dims=1)\n","        # Encode the selected patches\n","        encoded_x = self.encoder(selected_patches[:, tf.newaxis, :])[:, 0, :]\n","        if init_sigma:\n","            distances = pairwise_distances(encoded_x)\n","            sigma = np.mean(distances) * sigma_mult\n","            self.kernel.sigma.assign(sigma)\n","        self.kdm_unit.c_x.assign(encoded_x)\n","        self.kdm_unit.c_y.assign(samples_y)\n","        self.kdm_unit.comp_w.assign(tf.ones((self.n_comp,)) / self.n_comp)\n","\n","    def visualize_attention(self, input):\n","        patches = self.patch_layer(input)\n","        encoded = self.encoder(patches)\n","        w = self.attention_layer(encoded)\n","        conv2dt = tf.keras.layers.Conv2DTranspose(filters=1,\n","            kernel_size=self.patch_layer.patch_size,\n","            strides=self.patch_layer.strides,\n","            kernel_initializer=tf.keras.initializers.Ones(),\n","            bias_initializer=tf.keras.initializers.Zeros(),\n","            trainable=False)\n","        w = tf.reshape(w, [-1,\n","            self.patch_layer.num_patches,\n","            self.patch_layer.num_patches, 1])\n","        out = conv2dt(w)\n","        return out\n"]},{"cell_type":"markdown","metadata":{"id":"W8oGfy7lCfsa"},"source":["## Encoder"]},{"cell_type":"markdown","metadata":{"id":"tRiHC53KFvGP"},"source":["#### Creating encoder and encoder classifier for warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3BF_iAZba4vy"},"outputs":[],"source":["encoded_size = 128"]},{"cell_type":"markdown","metadata":{"id":"Vya8oVryOiir"},"source":["### Encoder that lets weights be loaded into it"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GB6devhTKMjM"},"outputs":[],"source":["def create_convnext_encoder(encoded_size):\n","  convnext = tf.keras.applications.convnext.ConvNeXtTiny(\n","    model_name='convnext_tiny',\n","    include_top=False,\n","    include_preprocessing=True,\n","    weights='imagenet',\n","    input_tensor=None,\n","    input_shape=(192,192,3),\n","    pooling=\"avg\",\n","    classes=6,\n","    classifier_activation='softmax'\n","  )\n","  encoder = keras.Sequential([\n","      Input(shape=(192, 192, 3)),\n","      convnext,\n","      keras.layers.Dropout(0.5),\n","      keras.layers.Dense(encoded_size, activation=\"relu\"), #relu, linear\n","  ])\n","\n","  return encoder"]},{"cell_type":"markdown","metadata":{"id":"ARXhRt3wOljo"},"source":["### Encoder with reshapes and loaded weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExUMo3bJhMuB"},"outputs":[],"source":["class Encoder(keras.Model):\n","\n","  def __init__(self, encoder):\n","    super().__init__()\n","    self.encoded_size = encoded_size\n","    self.encoder = encoder\n","\n","  def call(self, input): #(bs, n_patches, w*h*c)\n","    bs = tf.shape(input)[0] # bs\n","    input = tf.reshape(input,[-1,192,192,3]) # (bs * n_patches, w,h,c)\n","    x = self.encoder(input) #(bs * num_patches, encoded_size)\n","    out = tf.reshape(x, [bs, -1, self.encoded_size]) # (bs, num_patches, encoded_size)\n","    return out"]},{"cell_type":"markdown","metadata":{"id":"9d1acyOSFmJV"},"source":["### Instantiate the encoder that will go inside KDM and load pretrained weights to it"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13404,"status":"ok","timestamp":1690825505122,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"zEs3DzMeK2Le","outputId":"cad9a652-789f-4d50-a791-12a134e1ce35"},"outputs":[],"source":["with tf.device('/device:GPU:1'):\n","    convnext = create_convnext_encoder(encoded_size)\n","    encoder_kdm = Encoder(convnext)\n","    convnext.load_weights('/root/data/KDM/models/best_kdm_patch_convnext_extractor.h5')"]},{"cell_type":"markdown","metadata":{"id":"EEJFjUs0FQTt"},"source":["## Train the end-to-end model"]},{"cell_type":"markdown","metadata":{"id":"yTzQ5SawIcRl"},"source":["#### Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVs154mdHm3X"},"outputs":[],"source":["alpha = 0.001\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    f\"/root/data/KDM/models/regression_attn_KDM_alpha_{alpha}_0.5_dropout.h5\",\n","    monitor = \"val_loss\",\n","    verbose = 1,\n","    save_best_only = True,\n","    save_weights_only = True,\n","    mode = \"min\",\n","    save_freq=\"epoch\",\n",")\n","\n","earlystop = tf.keras.callbacks.EarlyStopping(\n","    monitor = \"val_loss\",\n","    patience = 4,\n","    verbose = 1,\n","    restore_best_weights=True,\n","    mode = \"min\",\n",")\n","#### Compiling the model\n","\n","def loss(y_true, y_pred):\n","  return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1])  +  alpha * y_pred[:, 1:2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPKa64ehdIIC"},"outputs":[],"source":["n_comp = 216\n","# for layer in encoder_kdm.layers:\n","#   layer.trainable = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# strategy = tf.distribute.MirroredStrategy()\n","# with strategy.scope():\n","with tf.device('/gpu:1'):\n","    kdm_class = KDMPatchRegressionModel(\n","                            patch_size=192,\n","                            image_size=1152,\n","                            strides=192,\n","                            encoded_size=encoded_size,\n","                            dim_y=6,\n","                            encoder=encoder_kdm,\n","                            n_comp=n_comp,\n","                            sigma=1.0,\n","                            attention=True,\n","                            attention_dim_h=64,\n","                            attention_dense_units_1=128,\n","                            attention_dense_units_2=128)\n","\n","    kdm_class.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n","                    loss=loss, metrics=['mean_absolute_error'])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9TnNCgssOvLQ"},"source":["#### Init components into the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3125,"status":"ok","timestamp":1690825593288,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"tu40zEpuar7_","outputId":"3106527a-6a39-4dc0-fc49-ce1afd242e28"},"outputs":[],"source":["kdm_class.init_components(prototypes, prototype_labels, init_sigma = True, sigma_mult = 1.)\n","print(kdm_class.kernel.sigma.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kdm_class(next(iter(train_dataset))[0])\n","kdm_class.load_weights(\"/root/data/KDM/checkpoints/regression_attn_KDM_alpha_0.001.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kdm_class.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### T-sNE visualization of encoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder_layer = kdm_class.get_layer('encoder')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out = kdm_class.predict(test_dataset)\n","y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_embeddings_list = []\n","y_true_list = []\n","\n","for x_batch, y_batch in test_dataset:\n","    embedding_batch = encoder_layer.predict(x_batch, verbose=0)\n","    test_embeddings_list.append(embedding_batch)\n","    y_true_list.append(y_batch)\n","\n","test_embeddings = np.concatenate(test_embeddings_list, axis=0)\n","y_true = np.concatenate(y_true_list, axis=0)\n","y_true_rounded = np.round(y_true * 5)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Average pooling embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label_mapping = {\n","    0: \"ISUP 0\",\n","    1: \"ISUP 1\",\n","    2: \"ISUP 2\",\n","    3: \"ISUP 3\",\n","    4: \"ISUP 4\",\n","    5: \"ISUP 5\"\n","}\n","\n","# Convert numeric labels to string labels\n","y_true_labels = np.vectorize(label_mapping.get)(y_true_rounded)\n","\n","# Average Pooling\n","test_embeddings_avg = np.mean(test_embeddings, axis=1)\n","\n","# Perform t-SNE dimensionality reduction\n","tsne_model = TSNE(n_components=2, random_state=0)\n","tsne_data = tsne_model.fit_transform(test_embeddings_avg)\n","\n","# Define your custom color palette\n","palette = sns.color_palette(\"Pastel1\", n_colors=6)\n","\n","# Plot using Seaborn\n","plt.figure(figsize=(10, 10))\n","sns.scatterplot(x=tsne_data[:, 0], y=tsne_data[:, 1], hue=y_true_labels, palette=palette, alpha=1)\n","plt.title('t-SNE Visualization of Encoder Layer (Colored by Ground Truth)')\n","plt.legend(title='ISUP Grade')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Continuos predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.colors import Normalize\n","\n","test_embeddings_list = []\n","y_true_list = []\n","y_pred_list = []\n","\n","for x_batch, y_batch in test_dataset:\n","    embedding_batch = encoder_layer.predict(x_batch, verbose=0)\n","    test_embeddings_list.append(embedding_batch)\n","    y_true_list.append(y_batch.numpy())\n","\n","    # Assuming kdm_class is your trained model for prediction\n","    out = kdm_class.predict(x_batch, verbose=0)\n","    y_pred, _ = out[:, 0], np.sqrt(out[:, 1])\n","    y_pred_list.append(y_pred)\n","\n","# Concatenate all the batches\n","test_embeddings = np.concatenate(test_embeddings_list, axis=0)\n","y_true = np.concatenate(y_true_list, axis=0)\n","y_pred = np.concatenate(y_pred_list, axis=0)\n","\n","# Average Pooling\n","test_embeddings_avg = np.mean(test_embeddings, axis=1)\n","\n","# Perform t-SNE dimensionality reduction\n","tsne_model = TSNE(n_components=2, random_state=0)\n","tsne_data = tsne_model.fit_transform(test_embeddings_avg)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Avg pooling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sns.set(style=\"white\")\n","\n","fig, ax = plt.subplots(figsize=(12, 12), dpi=300)\n","\n","# Create scatter plot using Seaborn\n","sns.scatterplot(x=tsne_data[:, 0], y=tsne_data[:, 1], hue=y_pred,\n","                palette=\"plasma\", ax=ax, s=60, edgecolor='w', legend=False)\n","\n","\n","# Add color bar manually using Matplotlib\n","norm = Normalize(vmin=np.min(y_pred), vmax=np.max(y_pred))\n","sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n","sm.set_array([])\n","\n","# Define colorbar position and dimensions [left, bottom, width, height]\n","cbar_ax = fig.add_axes([0.93, 0.2, 0.02, 0.6])\n","cbar = plt.colorbar(sm, cax=cbar_ax)\n","cbar.set_label('ISUP Grade', rotation=270, labelpad=20)\n","\n","# Set colorbar ticks and labels\n","cbar.set_ticks([np.min(y_pred),0.2,0.4,0.6,0.8, np.max(y_pred)])\n","cbar.set_ticklabels(['ISUP 0', 'ISUP 1', 'ISUP 2', 'ISUP 3', 'ISUP 4' ,'ISUP 5'])\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### MAx pooling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_embeddings_max = np.max(test_embeddings, axis=1)\n","\n","# Perform t-SNE dimensionality reduction\n","tsne_model = TSNE(n_components=2, random_state=0)\n","tsne_data = tsne_model.fit_transform(test_embeddings_max)\n","\n","sns.set(style=\"white\")\n","\n","fig, ax = plt.subplots(figsize=(12, 12), dpi=300)\n","\n","# Create scatter plot using Seaborn\n","sns.scatterplot(x=tsne_data[:, 0], y=tsne_data[:, 1], hue=y_pred,\n","                palette=\"plasma\", ax=ax, s=60, edgecolor='w', legend=False)\n","\n","\n","# Add color bar manually using Matplotlib\n","norm = Normalize(vmin=np.min(y_pred), vmax=np.max(y_pred))\n","sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n","sm.set_array([])\n","\n","# Define colorbar position and dimensions [left, bottom, width, height]\n","cbar_ax = fig.add_axes([0.93, 0.2, 0.02, 0.6])\n","cbar = plt.colorbar(sm, cax=cbar_ax)\n","cbar.set_label('ISUP Grade', rotation=270, labelpad=20)\n","\n","# Set colorbar ticks and labels\n","cbar.set_ticks([np.min(y_pred),0.2,0.4,0.6,0.8, np.max(y_pred)])\n","cbar.set_ticklabels(['ISUP 0', 'ISUP 1', 'ISUP 2', 'ISUP 3', 'ISUP 4' ,'ISUP 5'])\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### All patches asigned the same label of WSI"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_embeddings_list = []\n","y_true_list = []\n","\n","# Loop through test dataset to get embeddings and labels\n","for x_batch, y_batch in test_dataset:\n","    embedding_batch = encoder_layer.predict(x_batch, verbose=0)\n","    # Reshape each batch and append to list\n","    reshaped_embedding = embedding_batch.reshape(-1, 128)  # Flatten the first two dimensions\n","    test_embeddings_list.append(reshaped_embedding)\n","\n","    # Repeat labels to match each patch and append to list\n","    repeated_y = np.repeat(y_batch, embedding_batch.shape[1])\n","    y_true_list.append(repeated_y)\n","\n","# Concatenate all the batches\n","test_embeddings = np.vstack(test_embeddings_list)\n","y_true = np.concatenate(y_true_list)\n","y_true_rounded = np.round(y_true * 5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tsne_model = TSNE(n_components=2, random_state=0)\n","tsne_data = tsne_model.fit_transform(test_embeddings)\n","\n","sns.set(style=\"white\")\n","\n","fig, ax = plt.subplots(figsize=(12, 12), dpi=300)\n","\n","# Create scatter plot using Seaborn\n","sns.scatterplot(x=tsne_data[:, 0], y=tsne_data[:, 1], hue=y_true_rounded,\n","                palette=\"plasma\", ax=ax, s=60, edgecolor='w', legend=False)\n","\n","\n","# Add color bar manually using Matplotlib\n","norm = Normalize(vmin=np.min(y_pred), vmax=np.max(y_pred))\n","sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n","sm.set_array([])\n","\n","# Define colorbar position and dimensions [left, bottom, width, height]\n","cbar_ax = fig.add_axes([0.93, 0.2, 0.02, 0.6])\n","cbar = plt.colorbar(sm, cax=cbar_ax)\n","cbar.set_label('ISUP Grade', rotation=270, labelpad=20)\n","\n","# Set colorbar ticks and labels\n","cbar.set_ticks([np.min(y_pred),0.2,0.4,0.6,0.8, np.max(y_pred)])\n","cbar.set_ticklabels(['ISUP 0', 'ISUP 1', 'ISUP 2', 'ISUP 3', 'ISUP 4' ,'ISUP 5'])\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Bags are classified by patch model"]},{"cell_type":"markdown","metadata":{},"source":["#### patch model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def dm2comp(dm):\n","    '''\n","    Extract vectors and weights from a factorized density matrix representation\n","    Arguments:\n","     dm: tensor of shape (bs, n, d + 1)\n","    Returns:\n","     w: tensor of shape (bs, n)\n","     v: tensor of shape (bs, n, d)\n","    '''\n","    return dm[:, :, 0], dm[:, :, 1:]\n","\n","def comp2dm(w, v):\n","    '''\n","    Construct a factorized density matrix from vectors and weights\n","    Arguments:\n","     w: tensor of shape (bs, n)\n","     v: tensor of shape (bs, n, d)\n","    Returns:\n","     dm: tensor of shape (bs, n, d + 1)\n","    '''\n","    return tf.concat((w[:, :, tf.newaxis], v), axis=2)\n","\n","def samples2dm(samples):\n","    '''\n","    Construct a factorized density matrix from a batch of samples\n","    each sample will have the same weight. Samples that are all\n","    zero will be ignored.\n","    Arguments:\n","        samples: tensor of shape (bs, n, d)\n","    Returns:\n","        dm: tensor of shape (bs, n, d + 1)\n","    '''\n","    w = tf.reduce_any(samples, axis=-1)\n","    w = w / tf.reduce_sum(w, axis=-1, keepdims=True)\n","    return comp2dm(w, samples)\n","\n","def pure2dm(psi):\n","    '''\n","    Construct a factorized density matrix to represent a pure state\n","    Arguments:\n","     psi: tensor of shape (bs, d)\n","    Returns:\n","     dm: tensor of shape (bs, 1, d + 1)\n","    '''\n","    ones = tf.ones_like(psi[:, 0:1])\n","    dm = tf.concat((ones[:,tf.newaxis, :],\n","                    psi[:,tf.newaxis, :]),\n","                   axis=2)\n","    return dm\n","\n","def dm2discrete(dm):\n","    '''\n","    Creates a discrete distribution from the components of a density matrix\n","    Arguments:\n","     dm: tensor of shape (bs, n, d + 1)\n","    Returns:\n","     prob: vector of probabilities (bs, d)\n","    '''\n","    w, v = dm2comp(dm)\n","    w = w / tf.reduce_sum(w, axis=-1, keepdims=True)\n","    norms_v = tf.expand_dims(tf.linalg.norm(v, axis=-1), axis=-1)\n","    v = v / norms_v\n","    probs = tf.einsum('...j,...ji->...i', w, v ** 2, optimize=\"optimal\")\n","    return probs\n","\n","def dm2distrib(dm, sigma):\n","    '''\n","    Creates a Gaussian mixture distribution from the components of a density\n","    matrix with an RBF kernel\n","    Arguments:\n","     dm: tensor of shape (bs, n, d + 1)\n","     sigma: sigma parameter of the RBF kernel\n","    Returns:\n","     gm: mixture of Gaussian distribution with shape (bs, )\n","    '''\n","    w, v = dm2comp(dm)\n","    gm = tfd.MixtureSameFamily(reparameterize=True,\n","            mixture_distribution=tfd.Categorical(\n","                                    probs=w),\n","            components_distribution=tfd.Independent( tfd.Normal(\n","                    loc=v,  # component 2\n","                    scale=sigma / np.sqrt(2.)),\n","                    reinterpreted_batch_ndims=1))\n","    return gm\n","\n","def pure_dm_overlap(x, dm, kernel):\n","    '''\n","    Calculates the overlap of a state  \\phi(x) with a density\n","    matrix in a RKHS defined by a kernel\n","    Arguments:\n","      x: tensor of shape (bs, d)\n","     dm: tensor of shape (bs, n, d + 1)\n","     kernel: kernel function\n","              k: (bs, d) x (bs, n, d) -> (bs, n)\n","    Returns:\n","     overlap: tensor with shape (bs, )\n","    '''\n","    w, v = dm2comp(dm)\n","    overlap = tf.einsum('...i,...i->...', w, kernel(x, v) ** 2)\n","    return overlap\n","\n","class CompTransKernelLayer(tf.keras.layers.Layer):\n","    def __init__(self, transform, kernel):\n","        '''\n","        Composes a transformation and a kernel to create a new\n","        kernel.\n","        Arguments:\n","            transform: a function f that transform the input before feeding it to the\n","                    kernel\n","                    f:(bs, d) -> (bs, D)\n","            kernel: a kernel function\n","                    k:(bs, n, D)x(m, D) -> (bs, n, m)\n","        '''\n","        super(CompTransKernelLayer, self).__init__()\n","        self.transform = transform\n","        self.kernel = kernel\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        shape = tf.shape(A) # (bs, n, d)\n","        A = tf.reshape(A, [shape[0] * shape[1], shape[2]])\n","        A = self.transform(A)\n","        dim_out = tf.shape(A)[1]\n","        A = tf.reshape(A, [shape[0], shape[1], dim_out])\n","        B = self.transform(B)\n","        return self.kernel(A, B)\n","\n","    def log_weight(self):\n","        return self.kernel.log_weight()\n","\n","class RBFKernelLayer(tf.keras.layers.Layer):\n","    def __init__(self, sigma, dim, trainable=True, min_sigma=1e-3):\n","        '''\n","        Builds a layer that calculates the rbf kernel between two set of vectors\n","        Arguments:\n","            sigma: RBF scale parameter. If it is a tf.Variable it will be used as is.\n","                     Otherwise it will create a trainable variable with the given value.\n","        '''\n","        super(RBFKernelLayer, self).__init__()\n","        if type(sigma) is tf.Variable:\n","            self.sigma = sigma\n","        else:\n","            self.sigma = tf.Variable(sigma, dtype=tf.float32, trainable=trainable)\n","        self.dim = dim\n","        self.min_sigma = min_sigma\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        shape_A = tf.shape(A)\n","        shape_B = tf.shape(B)\n","        A_norm = tf.norm(A, axis=-1)[..., tf.newaxis] ** 2\n","        B_norm = tf.norm(B, axis=-1)[tf.newaxis, tf.newaxis, :] ** 2\n","        A_reshaped = tf.reshape(A, [-1, shape_A[2]])\n","        AB = tf.matmul(A_reshaped, B, transpose_b=True)\n","        AB = tf.reshape(AB, [shape_A[0], shape_A[1], shape_B[0]])\n","        dist2 = A_norm + B_norm - 2. * AB\n","        dist2 = tf.clip_by_value(dist2, 0., np.inf)\n","        sigma = tf.clip_by_value(self.sigma, self.min_sigma, np.inf)\n","        K = tf.exp(-dist2 / (2. * sigma ** 2.))\n","        return K\n","\n","    def log_weight(self):\n","        sigma = tf.clip_by_value(self.sigma, self.min_sigma, np.inf)\n","        return - self.dim * tf.math.log(sigma + 1e-12) - self.dim * np.log(4 * np.pi)\n","\n","class CosineKernelLayer(tf.keras.layers.Layer):\n","    def __init__(self):\n","        '''\n","        Builds a layer that calculates the cosine kernel between two set of vectors\n","        '''\n","        super(CosineKernelLayer, self).__init__()\n","        self.eps = 1e-6\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        A = tf.math.divide_no_nan(A,\n","                                  tf.expand_dims(tf.norm(A, axis=-1), axis=-1))\n","        B = tf.math.divide_no_nan(B,\n","                                  tf.expand_dims(tf.norm(B, axis=-1), axis=-1))\n","        K = tf.einsum(\"...nd,md->...nm\", A, B)\n","        return K\n","\n","    def log_weight(self):\n","        return 0\n","\n","class CrossProductKernelLayer(tf.keras.layers.Layer):\n","\n","    def __init__(self, dim1, kernel1, kernel2):\n","        '''\n","        Create a layer that calculates the cross product kernel of two input\n","        kernels. The input vector are divided into two parts, the first of dimension\n","        dim1 and the second of dimension d - dim1. Each input kernel is applied to\n","        one of the parts of the input.\n","        Arguments:\n","            dim1: the dimension of the first part of the input vector\n","            kernel1: a kernel function\n","                    k1:(bs, n, dim1)x(m, dim1) -> (bs, n, m)\n","            kernel2: a kernel function\n","                    k2:(bs, n, d - dim1)x(m, d - dim1) -> (bs, n, m)\n","        '''\n","\n","        super(CrossProductKernelLayer, self).__init__()\n","        self.dim1 = dim1\n","        self.kernel1 = kernel1\n","        self.kernel2 = kernel2\n","\n","    def call(self, A, B):\n","        '''\n","        Input:\n","            A: tensor of shape (bs, n, d)\n","            B: tensor of shape (m, d)\n","        Result:\n","            K: tensor of shape (bs, n, m)\n","        '''\n","        A1 = A[:, :, :self.dim1]\n","        A2 = A[:, :, self.dim1:]\n","        B1 = B[:, :self.dim1]\n","        B2 = B[:, self.dim1:]\n","        return self.kernel1(A1, B1) * self.kernel2(A2, B2)\n","\n","    def log_weight(self):\n","        return self.kernel1.log_weight() + self.kernel2.log_weight()\n","\n","def l1_loss(vals):\n","    '''\n","    Calculate the l1 loss for a batch of vectors\n","    Arguments:\n","        vals: tensor with shape (b_size, n)\n","    '''\n","    b_size = tf.cast(tf.shape(vals)[0], dtype=tf.float32)\n","    vals = vals / tf.norm(vals, axis=1)[:, tf.newaxis]\n","    loss = tf.reduce_sum(tf.abs(vals)) / b_size\n","    return loss\n","\n","class KDMUnit(tf.keras.layers.Layer):\n","    \"\"\"Kernel Density Matrix Unit\n","    Receives as input a factored density matrix represented by a set of vectors\n","    and weight values.\n","    Returns a resulting factored density matrix.\n","    Input shape:\n","        (batch_size, n_comp_in, dim_x + 1)\n","        where dim_x is the dimension of the input state\n","        and n_comp_in is the number of components of the input factorization.\n","        The weights of the input factorization of sample i are [i, :, 0],\n","        and the vectors are [i, :, 1:dim_x + 1].\n","    Output shape:\n","        (batch_size, n_comp, dim_y)\n","        where dim_y is the dimension of the output state\n","        and n_comp is the number of components used to represent the train\n","        density matrix. The weights of the\n","        output factorization for sample i are [i, :, 0], and the vectors\n","        are [i, :, 1:dim_y + 1].\n","    Arguments:\n","        dim_x: int. the dimension of the input state\n","        dim_y: int. the dimension of the output state\n","        x_train: bool. Whether to train or not the x compoments of the train\n","                       density matrix.\n","        x_train: bool. Whether to train or not the y compoments of the train\n","                       density matrix.\n","        w_train: bool. Whether to train or not the weights of the compoments\n","                       of the train density matrix.\n","        n_comp: int. Number of components used to represent\n","                 the train density matrix\n","        l1_act: float. Coefficient of the regularization term penalizing the l1\n","                       norm of the activations.\n","        l1_x: float. Coefficient of the regularization term penalizing the l1\n","                       norm of the x components.\n","        l1_y: float. Coefficient of the regularization term penalizing the l1\n","                       norm of the y components.\n","    \"\"\"\n","    def __init__(\n","            self,\n","            kernel,\n","            dim_x: int,\n","            dim_y: int,\n","            x_train: bool = True,\n","            y_train: bool = True,\n","            w_train: bool = True,\n","            n_comp: int = 0,\n","            l1_x: float = 0.,\n","            l1_y: float = 0.,\n","            l1_act: float = 0.,\n","            **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","        self.kernel = kernel\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.x_train = x_train\n","        self.y_train = y_train\n","        self.w_train = w_train\n","        self.n_comp = n_comp\n","        self.l1_x = l1_x\n","        self.l1_y = l1_y\n","        self.l1_act = l1_act\n","        self.c_x = self.add_weight(\n","            \"c_x\",\n","            shape=(self.n_comp, self.dim_x),\n","            #initializer=tf.keras.initializers.orthogonal(),\n","            initializer=tf.keras.initializers.random_normal(),\n","            trainable=self.x_train)\n","        self.c_y = self.add_weight(\n","            \"c_y\",\n","            shape=(self.n_comp, self.dim_y),\n","            initializer=tf.keras.initializers.Constant(np.sqrt(1./self.dim_y)),\n","            #initializer=tf.keras.initializers.random_normal(),\n","            trainable=self.y_train)\n","        self.comp_w = self.add_weight(\n","            \"comp_w\",\n","            shape=(self.n_comp,),\n","            initializer=tf.keras.initializers.constant(1./self.n_comp),\n","            trainable=self.w_train)\n","        self.eps = 1e-10\n","\n","    def call(self, inputs):\n","        # Weight regularizers\n","        if self.l1_x != 0:\n","            self.add_loss(self.l1_x * l1_loss(self.c_x))\n","        if self.l1_y != 0:\n","            self.add_loss(self.l1_y * l1_loss(self.c_y))\n","        #comp_w = tf.clip_by_value(self.comp_w, 1e-10, 1)\n","        comp_w = tf.abs(self.comp_w) + 1e-6\n","        # normalize comp_w to sum to 1\n","        comp_w = comp_w / tf.reduce_sum(comp_w)\n","        in_w = inputs[:, :, 0]  # shape (b, n_comp_in)\n","        in_v = inputs[:, :, 1:] # shape (b, n_comp_in, dim_x)\n","        out_vw = self.kernel(in_v, self.c_x)  # shape (b, n_comp_in, n_comp)\n","        out_w = (tf.expand_dims(tf.expand_dims(comp_w, axis=0), axis=0) *\n","                 tf.square(out_vw)) # shape (b, n_comp_in, n_comp)\n","        out_w = tf.maximum(out_w, self.eps) #########\n","        # out_w_sum = tf.maximum(tf.reduce_sum(out_w, axis=2), self.eps)  # shape (b, n_comp_in)\n","        out_w_sum = tf.reduce_sum(out_w, axis=2) # shape (b, n_comp_in)\n","        out_w = out_w / tf.expand_dims(out_w_sum, axis=2)\n","        out_w = tf.einsum('...i,...ij->...j', in_w, out_w, optimize=\"optimal\")\n","                # shape (b, n_comp)\n","        if self.l1_act != 0:\n","            self.add_loss(self.l1_act * l1_loss(out_w))\n","        out_w = tf.expand_dims(out_w, axis=-1) # shape (b, n_comp, 1)\n","        out_y_shape = tf.shape(out_w) + tf.constant([0, 0, self.dim_y - 1])\n","        out_y = tf.broadcast_to(tf.expand_dims(self.c_y, axis=0), out_y_shape)\n","        out = tf.concat((out_w, out_y), 2)\n","        return out\n","\n","    def get_config(self):\n","        config = {\n","            \"dim_x\": self.dim_x,\n","            \"dim_y\": self.dim_y,\n","            \"n_comp\": self.n_comp,\n","            \"x_train\": self.x_train,\n","            \"y_train\": self.y_train,\n","            \"w_train\": self.w_train,\n","            \"l1_x\": self.l1_x,\n","            \"l1_y\": self.l1_y,\n","            \"l1_act\": self.l1_act,\n","        }\n","        base_config = super().get_config()\n","        return {**base_config, **config}\n","\n","    def compute_output_shape(self, input_shape):\n","        return (self.dim_y + 1, self.n_comp)\n","\n","class KDMOverlap(tf.keras.layers.Layer):\n","    \"\"\"Kernel Density Matrix Overlap Unit\n","    Receives as input a vector and calculates its overlap with the unit density\n","    matrix.\n","    Input shape:\n","        (batch_size, dim_x)\n","        where dim_x is the dimension of the input state\n","    Output shape:\n","        (batch_size, )\n","    Arguments:\n","        kernel: a kernel function\n","        dim_x: int. the dimension of the input state\n","        x_train: bool. Whether to train the or not the compoments of the train\n","                       density matrix.\n","        w_train: bool. Whether to train the or not the weights of the compoments\n","                       of the train density matrix.\n","        n_comp: int. Number of components used to represent\n","                 the train density matrix\n","    \"\"\"\n","\n","    def __init__(\n","            self,\n","            kernel,\n","            dim_x: int,\n","            x_train: bool = True,\n","            w_train: bool = True,\n","            n_comp: int = 0,\n","            **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","        self.kernel = kernel\n","        self.dim_x = dim_x\n","        self.x_train = x_train\n","        self.w_train = w_train\n","        self.n_comp = n_comp\n","        self.c_x = self.add_weight(\n","            \"c_x\",\n","            shape=(self.n_comp, self.dim_x),\n","            #initializer=tf.keras.initializers.orthogonal(),\n","            initializer=tf.keras.initializers.random_normal(),\n","            trainable=self.x_train)\n","        self.comp_w = self.add_weight(\n","            \"comp_w\",\n","            shape=(self.n_comp,),\n","            initializer=tf.keras.initializers.constant(1./self.n_comp),\n","            trainable=self.w_train)\n","\n","    def call(self, inputs):\n","        #comp_w = tf.clip_by_value(self.comp_w, 1e-10, 1)\n","        comp_w = tf.abs(self.comp_w)\n","        # normalize comp_w to sum to 1\n","        comp_w = comp_w / tf.reduce_sum(comp_w)\n","        in_v = inputs[:, tf.newaxis, :]\n","        out_vw = self.kernel(in_v, self.c_x) ** 2 # shape (b, 1, n_comp)\n","        out_w = tf.einsum('...j,...ij->...', comp_w, out_vw, optimize=\"optimal\")\n","        return out_w\n","\n","    def get_config(self):\n","        config = {\n","            \"dim_x\": self.dim_x,\n","            \"n_comp\": self.n_comp,\n","            \"x_train\": self.x_train,\n","            \"w_train\": self.w_train,\n","        }\n","        base_config = super().get_config()\n","        return {**base_config, **config}\n","\n","    def compute_output_shape(self, input_shape):\n","        return (1,)\n","\n","class KDMClassModel(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 dim_y,\n","                 sigma,\n","                 n_comp,\n","                 x_train=True):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.n_comp = n_comp\n","        self.kernel_x = RBFKernelLayer(sigma, dim=dim_x)\n","        self.kdmu = KDMUnit(self.kernel_x,\n","                            dim_x=dim_x,\n","                            dim_y=dim_y,\n","                            n_comp=n_comp,\n","                            x_train=x_train)\n","\n","    def call(self, inputs):\n","        rho_x = pure2dm(inputs)\n","        rho_y = self.kdmu(rho_x)\n","        probs = dm2discrete(rho_y)\n","        return probs\n","\n","class BagKDMClassModel(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 dim_y,\n","                 sigma,\n","                 n_comp,\n","                 x_train=True,\n","                 l1_y=0.):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.n_comp = n_comp\n","        kernel_x = RBFKernelLayer(sigma)\n","        self.kdmu = KDMUnit(kernel_x,\n","                            dim_x=dim_x,\n","                            dim_y=dim_y,\n","                            n_comp=n_comp,\n","                            x_train=x_train,\n","                            l1_y=l1_y)\n","\n","    def call(self, inputs):\n","        in_shape = tf.shape(inputs)\n","        w = tf.ones_like(inputs[:, :, 0]) / in_shape[1]\n","        rho_x = comp2dm(w, inputs)\n","        rho_y = self.kdmu(rho_x)\n","        probs = dm2discrete(rho_y)\n","        return rho_y\n","\n","class KDMDenEstModel(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 sigma,\n","                 n_comp):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.n_comp = n_comp\n","        self.kernel = RBFKernelLayer(sigma, dim=dim_x)\n","        self.kdmover = KDMOverlap(self.kernel,\n","                                dim_x=dim_x,\n","                                n_comp=n_comp)\n","\n","    def call(self, inputs):\n","        log_probs = (tf.math.log(self.kdmover(inputs) + 1e-12)\n","                     + self.kernel.log_weight())\n","        self.add_loss(-tf.reduce_mean(log_probs))\n","        return log_probs\n","\n","class KDMDenEstModel2(tf.keras.Model):\n","    def __init__(self,\n","                 dim_x,\n","                 dim_y,\n","                 sigma,\n","                 n_comp,\n","                 trainable_sigma=True,\n","                 min_sigma=1e-3):\n","        super().__init__()\n","        self.dim_x = dim_x\n","        self.dim_y = dim_y\n","        self.n_comp = n_comp\n","        self.kernel_x = RBFKernelLayer(sigma, dim=dim_x,\n","                                       trainable=trainable_sigma,\n","                                       min_sigma=min_sigma)\n","        self.kernel_y = CosineKernelLayer()\n","        self.kernel = CrossProductKernelLayer(dim1=dim_x, kernel1=self.kernel_x, kernel2=self.kernel_y)\n","        self.kdmover = KDMOverlap(self.kernel,\n","                                dim_x=dim_x + dim_y,\n","                                n_comp=n_comp)\n","\n","    def call(self, inputs):\n","        log_probs = (tf.math.log(self.kdmover(inputs) + 1e-12)\n","                     + self.kernel.log_weight())\n","        self.add_loss(-tf.reduce_mean(log_probs))\n","        return log_probs\n","\n","class KQClassBagModel(tf.keras.Model):\n","    def __init__(self,\n","                 encoded_size,\n","                 dim_y,\n","                 encoder,\n","                 n_comp,\n","                 sigma=0.1,\n","                 mle_weight=0.):\n","        super().__init__()\n","        self.dim_y = dim_y\n","        self.encoded_size = encoded_size\n","        self.encoder = encoder\n","        self.n_comp = n_comp\n","        self.mle_weight = mle_weight\n","        self.kernel = RBFKernelLayer(sigma=sigma,\n","                                         dim=encoded_size,\n","                                         trainable=True)\n","        self.kdm_unit = KDMUnit(kernel=self.kernel,\n","                                       dim_x=encoded_size,\n","                                       dim_y=dim_y,\n","                                       n_comp=n_comp)\n","        self.regression_layer = ProbRegression()\n","\n","    def call(self, input):\n","        encoded = self.encoder(input)\n","        rho_x = pure2dm(encoded)\n","        rho_y = self.kdm_unit(rho_x)\n","        probs = dm2discrete(rho_y)\n","        mean_var = self.regression_layer(probs)\n","        return mean_var\n","\n","    def init_components(self, samples_x, samples_y, init_sigma=False, sigma_mult=1):\n","        encoded_x = self.encoder(samples_x)\n","        if init_sigma:\n","            distances = pairwise_distances(encoded_x)\n","            sigma = np.mean(distances) * sigma_mult\n","            self.kernel.sigma.assign(sigma)\n","        self.kdm_unit.c_x.assign(encoded_x)\n","        self.kdm_unit.c_y.assign(samples_y)\n","        self.kdm_unit.comp_w.assign(tf.ones((self.n_comp,)) / self.n_comp)\n","\n","encoded_size = 128\n","\n","def create_convnext_encoder(encoded_size):\n","  convnext = tf.keras.applications.convnext.ConvNeXtTiny(\n","    model_name='convnext_tiny',\n","    include_top=False,\n","    include_preprocessing=True,\n","    weights='imagenet',\n","    input_tensor=None,\n","    input_shape=(192,192,3),\n","    pooling=\"avg\",\n","    classes=5,\n","    classifier_activation='softmax'\n","  )\n","  encoder = keras.Sequential([\n","      Input(shape=(192, 192, 3)),\n","      convnext,\n","      keras.layers.Dropout(0.2),\n","      keras.layers.Dense(encoded_size, activation=\"tanh\"), #relu, linear\n","  ])\n","\n","  encoder_cls = keras.Sequential([encoder,\n","                                keras.layers.Dense(5, activation=\"softmax\")],\n","  )\n","  return encoder, encoder_cls\n","\n","\n","alpha = 0.1\n","def loss(y_true, y_pred):\n","  return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1])  +  alpha * y_pred[:, 1:2]\n","\n","\n","encoder_kdm, _ = create_convnext_encoder(encoded_size)\n","kdm_cls_patch = KQClassBagModel(\n","                encoded_size=encoded_size,\n","                dim_y=5,\n","                encoder=encoder_kdm,\n","                n_comp=n_comp,\n","                sigma=0.1)\n","kdm_cls_patch(np.zeros((1,192,192,3)))\n","\n","kdm_cls_patch.load_weights(\"/root/data/KDM/models/patch_regression_weights.h5\")\n","kdm_cls_patch.compile()"]},{"cell_type":"markdown","metadata":{},"source":["#### TSNE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_embeddings_list = []\n","y_pred_patch_list = []\n","\n","def break_into_patches(image, patch_size=192):\n","    # Assuming image is of shape (1152, 1152, 3)\n","    patches = []\n","    for i in range(0, image.shape[0], patch_size):\n","        for j in range(0, image.shape[1], patch_size):\n","            patch = image[i:i+patch_size, j:j+patch_size, :]\n","            patches.append(patch)\n","    return np.array(patches)\n","\n","# Loop through test dataset to get embeddings and labels\n","for x_batch, y_batch in test_dataset:\n","    \n","    # Get embeddings from the encoder layer\n","    embedding_batch = encoder_layer.predict(x_batch, verbose=0)\n","    \n","    # Reshape each batch and append to list\n","    reshaped_embedding = embedding_batch.reshape(-1, 128)  # Flatten the first two dimensions\n","    test_embeddings_list.append(reshaped_embedding)\n","    \n","    # Break each image into patches\n","    all_patches = []\n","    for image in x_batch:\n","        patches = break_into_patches(image)\n","        all_patches.extend(patches)\n","    \n","    all_patches = np.array(all_patches)\n","    \n","    # Get labels for each patch and append to list\n","    y_pred_from_patches = kdm_cls_patch.predict(all_patches, verbose=0)\n","    y_pred_patch_list.append(y_pred_from_patches)\n","\n","# Concatenate all the batches\n","test_embeddings = np.vstack(test_embeddings_list)\n","y_pred_patches = np.concatenate(y_pred_patch_list)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.unique(np.round(y_pred_patches * 4))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_patches = y_pred_patches[:,0]\n","var_patches = y_pred_patches[:,1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rounded_pred_patches = np.round(pred_patches * 4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["min_variance = np.min(var_patches)\n","max_variance = np.max(var_patches)\n","normalized_variance = (var_patches - min_variance) / (max_variance - min_variance)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["normalized_variance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rounded_pred_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.unique(rounded_pred_patches)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tsne_model = TSNE(n_components=2, random_state=0)\n","tsne_data = tsne_model.fit_transform(test_embeddings)\n","\n","sns.set(style=\"white\")\n","\n","fig, ax = plt.subplots(figsize=(12, 12), dpi=300)\n","\n","# Create scatter plot using Seaborn\n","sns.scatterplot(x=tsne_data[:, 0], y=tsne_data[:, 1], hue=rounded_pred_patches,\n","                palette=\"plasma\", ax=ax, s=60, edgecolor='w', legend=False)\n","\n","\n","# Add color bar manually using Matplotlib\n","norm = Normalize(vmin=np.min(y_pred), vmax=np.max(y_pred))\n","sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n","sm.set_array([])\n","\n","# Define colorbar position and dimensions [left, bottom, width, height]\n","cbar_ax = fig.add_axes([0.93, 0.2, 0.02, 0.6])\n","cbar = plt.colorbar(sm, cax=cbar_ax)\n","cbar.set_label('ISUP Grade', rotation=270, labelpad=20)\n","\n","# Set colorbar ticks and labels\n","cbar.set_ticks([np.min(y_pred),0.25,0.5,0.75, np.max(y_pred)])\n","cbar.set_ticklabels(['Stroma', 'Benign', 'Gleason 3', 'Gleason 4', 'Gleason 5'])\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["low_variance_indices = np.where(var_patches < 0.05)[0]\n","filtered_tsne_data = tsne_data[low_variance_indices]\n","filtered_rounded_pred_patches = np.array(rounded_pred_patches)[low_variance_indices]\n","\n","sns.set(style=\"white\")\n","fig, ax = plt.subplots(figsize=(12, 12), dpi=300)\n","\n","# Create scatter plot using Seaborn for the filtered points\n","sns.scatterplot(x=filtered_tsne_data[:, 0], y=filtered_tsne_data[:, 1], \n","                hue=filtered_rounded_pred_patches, palette=\"plasma\", ax=ax, \n","                s=60, edgecolor='w', legend=False)\n","\n","# Add color bar manually using Matplotlib\n","norm = Normalize(vmin=np.min(y_pred), vmax=np.max(y_pred))\n","sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n","sm.set_array([])\n","\n","# Define colorbar position and dimensions [left, bottom, width, height]\n","cbar_ax = fig.add_axes([0.93, 0.2, 0.02, 0.6])\n","cbar = plt.colorbar(sm, cax=cbar_ax)\n","cbar.set_label('ISUP Grade', rotation=270, labelpad=20)\n","\n","# Set colorbar ticks and labels\n","cbar.set_ticks([np.min(y_pred), 0.25, 0.5, 0.75, np.max(y_pred)])\n","cbar.set_ticklabels(['Stroma', 'Benign', 'Gleason 3', 'Gleason 4', 'Gleason 5'])\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rounded_pred_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.unique(rounded_pred_patches)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","tsne_model = TSNE(n_components=2, random_state=0)\n","tsne_data = tsne_model.fit_transform(test_embeddings)\n","\n","sns.set(style=\"white\")\n","fig, ax = plt.subplots(figsize=(12, 12), dpi=300)\n","\n","# Create scatter plot using Matplotlib for variable alpha values\n","scatter = ax.scatter(tsne_data[:, 0], tsne_data[:, 1], c=rounded_pred_patches, \n","                     cmap=\"plasma\", s=60, edgecolor='w', alpha=normalized_variance)\n","\n","# Add color bar manually using Matplotlib\n","norm = Normalize(vmin=np.min(y_pred), vmax=np.max(y_pred))\n","sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n","sm.set_array([])\n","\n","# Define colorbar position and dimensions [left, bottom, width, height]\n","cbar_ax = fig.add_axes([0.93, 0.2, 0.02, 0.6])\n","cbar = plt.colorbar(sm, cax=cbar_ax)\n","cbar.set_label('Gleason pattern', rotation=270, labelpad=20)\n","\n","# Set colorbar ticks and labels\n","cbar.set_ticks([np.min(y_pred),0.25,0.5,0.75, np.max(y_pred)])\n","cbar.set_ticklabels(['Stroma', 'Benign', 'Gleason 3', 'Gleason 4', 'Gleason 5'])\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Gw1qXsQ0Ig7x"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5701852,"status":"error","timestamp":1690831295129,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"-F6mvpXvW39B","outputId":"0df5afad-1255-452d-8038-cb7913e27b96"},"outputs":[],"source":["#history = kdm_class.fit(train_dataset, validation_data=val_dataset, epochs=20, verbose=1, callbacks=[checkpoint_callback, earlystop])"]},{"cell_type":"markdown","metadata":{"id":"OaAek-LCEpNh"},"source":["### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECPoPduDjyUK"},"outputs":[],"source":["# kdm_class(next(iter(train_dataset))[0])\n","\n","# kdm_class.load_weights(\"/content/drive/MyDrive/data/kdm_data/regression_attn_KDM_patch_weights_no_alpha.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56188,"status":"ok","timestamp":1690831612539,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"Z3L_ek_JW8oL","outputId":"79bd6cac-5f9f-4b2f-8e9d-91f121df9e9a"},"outputs":[],"source":["out = kdm_class.predict(test_dataset)\n","y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","predictions = np.round(y_pred * 5)\n","y_true = np.round(np.concatenate([y for x,y in test_dataset], axis=0) * 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"executionInfo":{"elapsed":393,"status":"ok","timestamp":1690831612917,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"wviCKKGWUmRm","outputId":"63ddc21c-c185-4f33-e21c-757b984b7aaa"},"outputs":[],"source":["ConfusionMatrixDisplay.from_predictions(y_true, predictions, normalize='true', display_labels=['ISUP 0', 'ISUP 1', 'ISUP 2', 'ISUP 3', 'ISUP 4', 'ISUP 5'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wv_3fYzAmgUi"},"outputs":[],"source":["y_true_reg = np.concatenate([y for x,y in test_dataset], axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.unique(y_true_reg)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690831614139,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"3ncT_TZDjnWc","outputId":"7f5493bd-a380-4274-9fc8-22d6c05667a3"},"outputs":[],"source":["mean_absolute_error(y_true_reg, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1690831614139,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"i31HMXhRiw0N","outputId":"38f9c9b8-57e6-4c89-fb3e-938a7bb3d53e"},"outputs":[],"source":["cohen_kappa_score(y_true, predictions, weights='quadratic')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1690831614431,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"NP0lqE6nkW2e","outputId":"7160354b-eb7e-48b8-fe3f-0377eddd39ae"},"outputs":[],"source":["print(classification_report(y_true, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your existing code\n","out = kdm_class.predict(test_dataset)\n","y_pred, var = out[:, 0], out[:, 1]\n","predictions = np.round(y_pred * 5)\n","y_true = np.round(np.concatenate([y for x,y in test_dataset], axis=0) * 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","\n","abs_errors = np.abs(predictions - y_true)\n","\n","# Group predictions and variance by absolute error\n","data_to_plot = {'Error Group': [], 'Variance': [], 'Predictions': []}\n","for i, error in enumerate(abs_errors):\n","    if error == 0:\n","        error_group = '0'\n","    elif error == 1:\n","        error_group = '1'\n","    else:\n","        error_group = '2+'\n","\n","    data_to_plot['Error Group'].append(error_group)\n","    data_to_plot['Variance'].append(var[i])\n","    data_to_plot['Predictions'].append(predictions[i])\n","\n","# Create a DataFrame\n","df = pd.DataFrame(data_to_plot)\n","\n","# Get the counts for each error group\n","counts = df['Error Group'].value_counts().loc[['0', '1', '2+']]\n","# Define the color palette\n","palette = sns.color_palette(\"Pastel1\", n_colors=3)\n","\n","# Plot the variance using seaborn\n","plt.figure(figsize=(10, 6))\n","sns.violinplot(x='Error Group', y='Variance', data=df, order=['0', '1', '2+'], palette=palette)\n","plt.title('Variance by Absolute Error Group', fontsize=15)\n","plt.xlabel('Error Group', fontsize=13)\n","plt.ylabel('Variance', fontsize=13)\n","\n","# Create custom legend\n","legend_labels = [f'{key}: {value} samples' for key, value in counts.items()]\n","legend_handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=palette[i], markersize=10) for i in range(3)]\n","plt.legend(legend_handles, legend_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n","\n","plt.savefig('variance_plot.png', bbox_inches='tight', dpi=600)\n","plt.show()\n","\n","# Plot the predictions using seaborn\n","plt.figure(figsize=(10, 6))\n","sns.violinplot(x='Error Group', y='Predictions', data=df, order=['0', '1', '2+'], palette=palette)\n","plt.title('Predictions by Absolute Error Group', fontsize=15)\n","plt.xlabel('Error Group', fontsize=13)\n","plt.ylabel('Predictions', fontsize=13)\n","\n","# Create custom legend\n","plt.legend(legend_handles, legend_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n","\n","plt.savefig('predictions_plot.png', bbox_inches='tight', dpi=600)\n","plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419,"referenced_widgets":["55682f7d475d48518553ba5456afe34a","23bb8997e3f24a4cae1894cda27d90c4","27446c0824bd4751b085495bed9cc936","4b193d85d37b455ebc069a2172d8de13","3755d91cb05442b2a2da7ce83be8c2b1","45966831d0d14741b705e140fa2f8b00","dc3c84e22d9544b99ae0f6e08054911c","a0c6b684211e4ad4afd0424ed8c06e44"]},"executionInfo":{"elapsed":4664,"status":"ok","timestamp":1689223430057,"user":{"displayName":"Sebastian Medina","userId":"05516782838817459210"},"user_tz":240},"id":"OEc5rbbHhqAK","outputId":"29fa3ac9-559f-493c-ef03-be10e354d85d"},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["### Inference of classification models to extract metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class KDMPatchClassModel(tf.keras.Model):\n","    def __init__(self,\n","                 patch_size,\n","                 image_size,\n","                 strides,\n","                 encoder,\n","                 encoded_size,\n","                 dim_y,\n","                 n_comp,\n","                 sigma=0.1,\n","                 attention=False,\n","                 attention_dim_h=64,\n","                 attention_dense_units_1=64,\n","                 attention_dense_units_2=64):\n","        super().__init__()\n","        self.patch_size = patch_size\n","        self.image_size = image_size\n","        self.strides = strides\n","        self.patch_layer = Patches(patch_size, image_size, strides)\n","        self.dim_y = dim_y\n","        self.encoded_size = encoded_size\n","        self.encoder = encoder\n","        self.n_comp = n_comp\n","        self.attention = attention\n","        self.kernel = RBFKernelLayer(sigma=sigma,\n","                                         dim=encoded_size,\n","                                         trainable=True)\n","        self.kdm_unit = KDMUnit(kernel=self.kernel,\n","                                       dim_x=encoded_size,\n","                                       dim_y=dim_y,\n","                                       n_comp=n_comp)\n","        if attention:\n","            self.attention_layer = KDMAttentionLayer(dim_h=attention_dim_h,\n","                                              dense_units_1=attention_dense_units_1,\n","                                              dense_units_2=attention_dense_units_2)\n","    def call(self, input): # (bs, 1152,1152,3)\n","        patches = self.patch_layer(input) #(bs, n_patches, w*h*c)\n","        encoded = self.encoder(patches) #()\n","        bs = tf.shape(encoded)[0]\n","        if self.attention:\n","            w = self.attention_layer(encoded)\n","        else:\n","            w = tf.ones((bs, self.patch_layer.num_patches ** 2,)) / (self.patch_layer.num_patches ** 2)\n","        rho_x = comp2dm(w, encoded)\n","        rho_y = self.kdm_unit(rho_x)\n","        probs = dm2discrete(rho_y)\n","        return probs\n","\n","    def init_components(self, samples_x, samples_y, init_sigma=False, sigma_mult=1):\n","        patches = self.patch_layer(samples_x)\n","        idx = tf.random.uniform(shape=(patches.shape[0],), maxval=patches.shape[1], dtype=tf.int32) #select 1 random patch from each mosaic\n","        # Select the desired patches using tf.gather\n","        selected_patches = tf.gather(patches, idx, axis=1, batch_dims=1)\n","        # Encode the selected patches\n","        encoded_x = self.encoder(selected_patches[:, tf.newaxis, :])[:, 0, :]\n","        if init_sigma:\n","            distances = pairwise_distances(encoded_x)\n","            sigma = np.mean(distances) * sigma_mult\n","            self.kernel.sigma.assign(sigma)\n","        self.kdm_unit.c_x.assign(encoded_x)\n","        self.kdm_unit.c_y.assign(samples_y)\n","        self.kdm_unit.comp_w.assign(tf.ones((self.n_comp,)) / self.n_comp)\n","\n","    def visualize_attention(self, input):\n","        patches = self.patch_layer(input)\n","        encoded = self.encoder(patches)\n","        w = self.attention_layer(encoded)\n","        conv2dt = tf.keras.layers.Conv2DTranspose(filters=1,\n","            kernel_size=self.patch_layer.patch_size,\n","            strides=self.patch_layer.strides,\n","            kernel_initializer=tf.keras.initializers.Ones(),\n","            bias_initializer=tf.keras.initializers.Zeros(),\n","            trainable=False)\n","        w = tf.reshape(w, [-1,\n","            self.patch_layer.num_patches,\n","            self.patch_layer.num_patches, 1])\n","        out = conv2dt(w)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kdm_classifier = KDMPatchClassModel(\n","                        patch_size=192,\n","                        image_size=1152,\n","                        strides=192,\n","                        encoded_size=encoded_size,\n","                        dim_y=6,\n","                        encoder=encoder_kdm,\n","                        n_comp=n_comp,\n","                        sigma=1.0,\n","                        attention=True,\n","                        attention_dim_h=64,\n","                        attention_dense_units_1=128,\n","                        attention_dense_units_2=128)\n","\n","kdm_classifier.compile()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kdm_classifier(next(iter(train_dataset))[0])\n","\n","kdm_classifier.load_weights(\"/data/KDM/models/attn_kdm_cls_from_kdm_patch_cls_unfrozen.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds = kdm_classifier.predict(test_dataset)\n","predictions = np.argmax(preds, axis =1)\n","y_true = np.round(np.concatenate([y for x,y in test_dataset], axis=0) * 5)\n","ConfusionMatrixDisplay.from_predictions(y_true, predictions, normalize='true', display_labels=['ISUP 0', 'ISUP 1', 'ISUP 2', 'ISUP 3', 'ISUP 4', 'ISUP 5'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_true_reg = np.concatenate([y for x,y in test_dataset], axis=0)\n","preds_regression = predictions / 5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds_regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mean_absolute_error(y_true_reg, preds_regression)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["k97E2G2wHQuC","Q1kX_0gPQdng","9tqHmJGVGlUw","WDlpe7ryGc-6","8Tnwlxs2GQQK","_DyOstFfOP20"],"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1dC_Eqi9NYdX6uFHXaDegu3v-jMuTUg_G","timestamp":1690550924877},{"file_id":"1EikY24MvleSagDzzw5wT7S18IN2Qp0d-","timestamp":1685982030546}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"23bb8997e3f24a4cae1894cda27d90c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3755d91cb05442b2a2da7ce83be8c2b1","placeholder":"​","style":"IPY_MODEL_45966831d0d14741b705e140fa2f8b00","value":"0.002 MB of 0.023 MB uploaded (0.000 MB deduped)\r"}},"27446c0824bd4751b085495bed9cc936":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc3c84e22d9544b99ae0f6e08054911c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0c6b684211e4ad4afd0424ed8c06e44","value":0.09354552746000254}},"3755d91cb05442b2a2da7ce83be8c2b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45966831d0d14741b705e140fa2f8b00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b193d85d37b455ebc069a2172d8de13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55682f7d475d48518553ba5456afe34a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_23bb8997e3f24a4cae1894cda27d90c4","IPY_MODEL_27446c0824bd4751b085495bed9cc936"],"layout":"IPY_MODEL_4b193d85d37b455ebc069a2172d8de13"}},"a0c6b684211e4ad4afd0424ed8c06e44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc3c84e22d9544b99ae0f6e08054911c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
